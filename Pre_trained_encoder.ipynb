{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99575a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras \n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60e67a1",
   "metadata": {},
   "source": [
    "<b>LOADING AND PREPROCESSING THE DATASET</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f122a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 540 files belonging to 1 classes.\n",
      "Using 486 files for training.\n",
      "Using 54 files for validation.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "image_size = (28,28)\n",
    "root_dir = 'D:\\\\Documents\\\\DATA_SET_FOR_RELEASE\\\\renamed\\\\all_train'\n",
    "train_ds, val_ds = tf.keras.preprocessing.image_dataset_from_directory(root_dir,\n",
    "  image_size=image_size,\n",
    "  batch_size=batch_size,\n",
    "  label_mode=None,\n",
    "  validation_split=0.1,\n",
    "  subset = 'both',\n",
    "  seed = 45)\n",
    "\n",
    "\n",
    " \n",
    "normalization_layer = layers.Rescaling(scale= 1./255) \n",
    " \n",
    "normalized_train_ds = train_ds.map(lambda x: normalization_layer(x))\n",
    "normalized_val_ds = val_ds.map(lambda x: normalization_layer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12f410",
   "metadata": {},
   "source": [
    "  <b>DEFINE SAMPLING TECHNIQUE FOR THE LATENT SPACE</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f460f052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12b47975",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sampling_reparameterization function--- Function for generating samples\n",
    "def sampling_reparameterization(distribution_params):\n",
    "    mean, log_var = distribution_params\n",
    "    epsilon = tf.keras.backend.random_normal(shape=tf.keras.backend.shape(mean), mean=0., stddev=1.)\n",
    "    z = mean + tf.keras.backend.exp(log_var / 2) * epsilon\n",
    "    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755082fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the sampling network\n",
    "latent_dim = 10 #dimension of the latent space\n",
    "def sampling(input_1,input_2):\n",
    "    mean = keras.Input(shape=input_1, name='input_layer1')\n",
    "    log_var = keras.Input(shape=input_2, name='input_layer2')\n",
    "    out = layers.Lambda(sampling_reparameterization, name='encoder_output')([mean, log_var])\n",
    "    enc_2 = tf.keras.Model([mean,log_var], out,  name=\"Encoder_2\")\n",
    "    \n",
    "    return enc_2\n",
    "sampler = sampling(latent_dim, latent_dim)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b32ef",
   "metadata": {},
   "source": [
    "<b>DEFINE LOSS FUNCTION AND OPTIMIZER FOR TRAINING</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the initial learning rate and the decay rate\n",
    "initial_learning_rate = 0.0008\n",
    "decay_steps = 400\n",
    "decay_rate = 0.8\n",
    "staircase = True\n",
    "\n",
    "# Create the learning rate schedule\n",
    "learning_rate_fn = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,decay_steps, decay_rate, staircase=staircase)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer_1 = tf.optimizers.Adam(learning_rate=learning_rate_fn)\n",
    "optimizer_2 = tf.optimizers.Adam(learning_rate=learning_rate_fn)\n",
    "\n",
    "#Define scaling factor for loss functions\n",
    "beta = 1000\n",
    " \n",
    "def mse_loss(y_true, y_pred):\n",
    "    r_loss = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred), axis = [1,2,3])\n",
    "    return r_loss\n",
    " \n",
    "def kl_loss(mean, log_var):\n",
    "    kl_loss =  -0.5 * tf.keras.backend.sum(1 + log_var - tf.keras.backend.square(mean) - tf.keras.backend.exp(log_var), axis = 1)\n",
    "    return kl_loss\n",
    " \n",
    "def vae_loss(y_true, y_pred, mean, log_var):\n",
    "    r_loss = mse_loss(y_true, y_pred)\n",
    "    KL_loss = kl_loss(mean, log_var)\n",
    "    training_loss = (beta*r_loss) + KL_loss\n",
    "    \n",
    "    return training_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1aa1f5",
   "metadata": {},
   "source": [
    " <b>BUILDING THE ENCODER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c635be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None, 28, 28, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " resizing_1 (Resizing)          (None, 32, 32, 3)    0           ['input_layer[0][0]']            \n",
      "                                                                                                  \n",
      " resnet50v2 (Functional)        (None, 1, 1, 2048)   23564800    ['resizing_1[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 2048)        0           ['resnet50v2[0][0]']             \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           20490       ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           20490       ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,605,780\n",
      "Trainable params: 40,980\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the encoder\n",
    "def encoder(input_encoder):\n",
    "    inputs = keras.Input(shape=input_encoder, name='input_layer')\n",
    "    reshape = keras.layers.Resizing(32,32)(inputs)\n",
    "    base_model = keras.applications.ResNet50V2(weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "                                             input_shape=(32,32,3),\n",
    "                                             include_top=False)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    x = base_model(reshape, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    mean = keras.layers.Dense(10)(x)\n",
    "    log_var = keras.layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs,(mean, log_var), name = 'Encoder')\n",
    "    \n",
    "    return model\n",
    "\n",
    "enc = encoder((*image_size,3))\n",
    "enc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b769fa97",
   "metadata": {},
   "source": [
    " <b>BUILDING THE DECODER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fbe5502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               1100      \n",
      "                                                                 \n",
      " lrelu_A (LeakyReLU)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 600)               60600     \n",
      "                                                                 \n",
      " lrelu_B (LeakyReLU)         (None, 600)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3136)              1884736   \n",
      "                                                                 \n",
      " lrelu_C (LeakyReLU)         (None, 3136)              0         \n",
      "                                                                 \n",
      " Reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv_transpose_1 (Conv2DTra  (None, 7, 7, 64)         36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " bn_A (BatchNormalization)   (None, 7, 7, 64)          256       \n",
      "                                                                 \n",
      " lrelu_D (LeakyReLU)         (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv_transpose_2 (Conv2DTra  (None, 14, 14, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " bn_B (BatchNormalization)   (None, 14, 14, 64)        256       \n",
      "                                                                 \n",
      " lrelu_E (LeakyReLU)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv_transpose_3 (Conv2DTra  (None, 28, 28, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " bn_C (BatchNormalization)   (None, 28, 28, 64)        256       \n",
      "                                                                 \n",
      " lrelu_F (LeakyReLU)         (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " conv_transpose_5 (Conv2DTra  (None, 28, 28, 3)        1731      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,059,719\n",
      "Trainable params: 2,059,335\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the decoder\n",
    "def decoder(input_decoder):\n",
    "     \n",
    "    inputs = keras.Input(shape=input_decoder, name='input_layer')\n",
    "  \n",
    "    x = layers.Dense(100, name='dense_1')(inputs)\n",
    "    x = layers.LeakyReLU(name='lrelu_A')(x)\n",
    "\n",
    "    x = layers.Dense(600, name='dense_2')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_B')(x)\n",
    "\n",
    "    x = layers.Dense(3136, name='dense_3')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_C')(x)\n",
    "    x = layers.Reshape((7,7,64), name='Reshape')(x)\n",
    "     \n",
    "    # Block-1\n",
    "    x = layers.Conv2DTranspose(64, 3, strides= 1, padding='same',name='conv_transpose_1')(x)\n",
    "    x = layers.BatchNormalization(name='bn_A')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_D')(x)\n",
    "\n",
    "    \n",
    "    # Block-2\n",
    "    x = layers.Conv2DTranspose(64, 3, strides= 2, padding='same', name='conv_transpose_2')(x)\n",
    "    x = layers.BatchNormalization(name='bn_B')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_E')(x)\n",
    "  \n",
    "  \n",
    "    # Block-3\n",
    "    x = layers.Conv2DTranspose(64, 3, 2, padding='same', name='conv_transpose_3')(x)\n",
    "    x = layers.BatchNormalization(name='bn_C')(x)\n",
    "    x = layers.LeakyReLU(name='lrelu_F')(x)\n",
    "       \n",
    "    # Block-5\n",
    "    outputs = layers.Conv2DTranspose(3, 3, 1,padding='same', activation='sigmoid', name='conv_transpose_5')(x)\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"Decoder\")\n",
    "    return model\n",
    "    print(dec.summary())\n",
    "dec = decoder((latent_dim,))\n",
    "dec.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f65ea",
   "metadata": {},
   "source": [
    " <b>DEFINE CUSTOM TRAINING LOOP</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a10f65e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(train_images):\n",
    " \n",
    "    with tf.GradientTape() as encoder, tf.GradientTape() as decoder:\n",
    "       \n",
    "       \n",
    "        mean, log_var = enc(train_images, training=True)\n",
    "        latent = sampler([mean, log_var])\n",
    "        generated_images = dec(latent, training=True)\n",
    "        loss = vae_loss(train_images, generated_images, mean, log_var)\n",
    "        MSE =  mse_loss(train_images, generated_images)\n",
    "        KLE = kl_loss(mean, log_var)\n",
    "\n",
    "         \n",
    "    gradients_of_enc = encoder.gradient(loss, enc.trainable_variables)\n",
    "    gradients_of_dec = decoder.gradient(loss, dec.trainable_variables)\n",
    "     \n",
    "    optimizer_1.apply_gradients(zip(gradients_of_enc, enc.trainable_variables))\n",
    "    optimizer_2.apply_gradients(zip(gradients_of_dec, dec.trainable_variables))\n",
    "    return loss,MSE,KLE\n",
    "\n",
    "\n",
    "def val_step(val_images):\n",
    "  mean, log_var = enc(val_images)\n",
    "  latent = sampler([mean, log_var])\n",
    "  generated_images_val = dec(latent)\n",
    "  val_loss = mse_loss(val_images, generated_images_val)\n",
    "\n",
    "  return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "510cb816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 || Training Loss:33.7386 || MSE:0.0467 || KL_Loss: 1.0568 || Val_MSE:0.0573 || time 25.4411\n",
      "epoch: 2 || Training Loss:23.6832 || MSE:0.0327 || KL_Loss: 0.7945 || Val_MSE:0.0530 || time 7.7535\n",
      "epoch: 3 || Training Loss:21.1434 || MSE:0.0289 || KL_Loss: 0.9128 || Val_MSE:0.0472 || time 10.6974\n",
      "epoch: 4 || Training Loss:19.3232 || MSE:0.0259 || KL_Loss: 1.1810 || Val_MSE:0.0361 || time 12.8938\n",
      "epoch: 5 || Training Loss:18.8715 || MSE:0.0250 || KL_Loss: 1.3772 || Val_MSE:0.0400 || time 13.5897\n",
      "epoch: 6 || Training Loss:17.9049 || MSE:0.0232 || KL_Loss: 1.6515 || Val_MSE:0.0274 || time 13.3901\n",
      "epoch: 7 || Training Loss:17.3214 || MSE:0.0221 || KL_Loss: 1.8171 || Val_MSE:0.0280 || time 12.8878\n",
      "epoch: 8 || Training Loss:17.3952 || MSE:0.0222 || KL_Loss: 1.8431 || Val_MSE:0.0271 || time 14.9783\n",
      "epoch: 9 || Training Loss:16.3802 || MSE:0.0209 || KL_Loss: 1.7390 || Val_MSE:0.0266 || time 15.7041\n",
      "epoch: 10 || Training Loss:15.7185 || MSE:0.0200 || KL_Loss: 1.7074 || Val_MSE:0.0319 || time 15.3851\n",
      "epoch: 11 || Training Loss:16.4234 || MSE:0.0211 || KL_Loss: 1.6426 || Val_MSE:0.0245 || time 15.3775\n",
      "epoch: 12 || Training Loss:15.7409 || MSE:0.0200 || KL_Loss: 1.7579 || Val_MSE:0.0292 || time 15.1040\n",
      "epoch: 13 || Training Loss:16.9756 || MSE:0.0217 || KL_Loss: 1.7995 || Val_MSE:0.0240 || time 15.2506\n",
      "epoch: 14 || Training Loss:15.6563 || MSE:0.0198 || KL_Loss: 1.7884 || Val_MSE:0.0210 || time 15.0891\n",
      "epoch: 15 || Training Loss:15.5974 || MSE:0.0197 || KL_Loss: 1.8023 || Val_MSE:0.0272 || time 15.2354\n",
      "epoch: 16 || Training Loss:15.4931 || MSE:0.0195 || KL_Loss: 1.8370 || Val_MSE:0.0254 || time 15.2031\n",
      "epoch: 17 || Training Loss:14.8823 || MSE:0.0186 || KL_Loss: 1.8881 || Val_MSE:0.0282 || time 15.3285\n",
      "epoch: 18 || Training Loss:15.1320 || MSE:0.0190 || KL_Loss: 1.8566 || Val_MSE:0.0229 || time 15.0775\n",
      "epoch: 19 || Training Loss:15.3685 || MSE:0.0191 || KL_Loss: 2.0092 || Val_MSE:0.0232 || time 15.3175\n",
      "epoch: 20 || Training Loss:14.4114 || MSE:0.0177 || KL_Loss: 1.9925 || Val_MSE:0.0226 || time 15.0389\n",
      "epoch: 21 || Training Loss:14.5764 || MSE:0.0179 || KL_Loss: 2.0442 || Val_MSE:0.0231 || time 14.9084\n",
      "epoch: 22 || Training Loss:13.9125 || MSE:0.0170 || KL_Loss: 2.0145 || Val_MSE:0.0246 || time 14.5103\n",
      "epoch: 23 || Training Loss:14.7718 || MSE:0.0182 || KL_Loss: 1.9973 || Val_MSE:0.0225 || time 9.1223\n",
      "epoch: 24 || Training Loss:14.4663 || MSE:0.0178 || KL_Loss: 1.9874 || Val_MSE:0.0220 || time 8.2958\n",
      "epoch: 25 || Training Loss:14.4611 || MSE:0.0177 || KL_Loss: 2.0453 || Val_MSE:0.0218 || time 7.9946\n",
      "epoch: 26 || Training Loss:13.5720 || MSE:0.0166 || KL_Loss: 1.9243 || Val_MSE:0.0222 || time 8.2324\n",
      "epoch: 27 || Training Loss:14.6347 || MSE:0.0181 || KL_Loss: 1.9876 || Val_MSE:0.0220 || time 7.5564\n",
      "epoch: 28 || Training Loss:14.4243 || MSE:0.0177 || KL_Loss: 2.0355 || Val_MSE:0.0224 || time 8.2684\n",
      "epoch: 29 || Training Loss:14.2084 || MSE:0.0174 || KL_Loss: 2.0379 || Val_MSE:0.0226 || time 7.9315\n",
      "epoch: 30 || Training Loss:13.5578 || MSE:0.0164 || KL_Loss: 2.0807 || Val_MSE:0.0193 || time 7.6198\n",
      "epoch: 31 || Training Loss:13.5125 || MSE:0.0163 || KL_Loss: 2.1069 || Val_MSE:0.0233 || time 7.6819\n",
      "epoch: 32 || Training Loss:13.8309 || MSE:0.0168 || KL_Loss: 2.0663 || Val_MSE:0.0235 || time 8.4783\n",
      "epoch: 33 || Training Loss:14.2689 || MSE:0.0175 || KL_Loss: 2.0185 || Val_MSE:0.0216 || time 7.7751\n",
      "epoch: 34 || Training Loss:13.6351 || MSE:0.0165 || KL_Loss: 2.0621 || Val_MSE:0.0205 || time 8.0728\n",
      "epoch: 35 || Training Loss:14.4356 || MSE:0.0176 || KL_Loss: 2.0970 || Val_MSE:0.0230 || time 7.8707\n",
      "epoch: 36 || Training Loss:14.2255 || MSE:0.0173 || KL_Loss: 2.1368 || Val_MSE:0.0226 || time 8.1184\n",
      "epoch: 37 || Training Loss:13.4122 || MSE:0.0162 || KL_Loss: 2.0998 || Val_MSE:0.0270 || time 7.6536\n",
      "epoch: 38 || Training Loss:14.0958 || MSE:0.0170 || KL_Loss: 2.2264 || Val_MSE:0.0205 || time 8.1190\n",
      "epoch: 39 || Training Loss:14.1613 || MSE:0.0172 || KL_Loss: 2.0895 || Val_MSE:0.0226 || time 7.9865\n",
      "epoch: 40 || Training Loss:13.6702 || MSE:0.0165 || KL_Loss: 2.1195 || Val_MSE:0.0217 || time 8.3021\n",
      "epoch: 41 || Training Loss:13.6205 || MSE:0.0164 || KL_Loss: 2.1637 || Val_MSE:0.0199 || time 7.5769\n",
      "epoch: 42 || Training Loss:13.1535 || MSE:0.0157 || KL_Loss: 2.1314 || Val_MSE:0.0224 || time 7.9830\n",
      "epoch: 43 || Training Loss:13.8660 || MSE:0.0168 || KL_Loss: 2.1409 || Val_MSE:0.0224 || time 7.5821\n",
      "epoch: 44 || Training Loss:13.6430 || MSE:0.0164 || KL_Loss: 2.1518 || Val_MSE:0.0212 || time 7.7528\n",
      "epoch: 45 || Training Loss:13.7087 || MSE:0.0165 || KL_Loss: 2.1741 || Val_MSE:0.0198 || time 7.7867\n",
      "epoch: 46 || Training Loss:13.4228 || MSE:0.0160 || KL_Loss: 2.2302 || Val_MSE:0.0206 || time 8.2529\n",
      "epoch: 47 || Training Loss:12.8360 || MSE:0.0152 || KL_Loss: 2.1770 || Val_MSE:0.0220 || time 7.4529\n",
      "epoch: 48 || Training Loss:13.2385 || MSE:0.0158 || KL_Loss: 2.2077 || Val_MSE:0.0216 || time 8.0195\n",
      "epoch: 49 || Training Loss:12.9570 || MSE:0.0154 || KL_Loss: 2.1584 || Val_MSE:0.0220 || time 8.1698\n",
      "epoch: 50 || Training Loss:13.3420 || MSE:0.0159 || KL_Loss: 2.2206 || Val_MSE:0.0185 || time 7.7697\n",
      "epoch: 51 || Training Loss:13.4733 || MSE:0.0162 || KL_Loss: 2.1563 || Val_MSE:0.0220 || time 7.5333\n",
      "epoch: 52 || Training Loss:13.1168 || MSE:0.0157 || KL_Loss: 2.1224 || Val_MSE:0.0222 || time 7.8057\n",
      "epoch: 53 || Training Loss:14.2607 || MSE:0.0172 || KL_Loss: 2.2109 || Val_MSE:0.0257 || time 7.8863\n",
      "epoch: 54 || Training Loss:13.3568 || MSE:0.0158 || KL_Loss: 2.3107 || Val_MSE:0.0232 || time 7.5862\n",
      "epoch: 55 || Training Loss:13.1673 || MSE:0.0157 || KL_Loss: 2.1966 || Val_MSE:0.0204 || time 7.9363\n",
      "epoch: 56 || Training Loss:13.1708 || MSE:0.0157 || KL_Loss: 2.1589 || Val_MSE:0.0265 || time 8.0521\n",
      "epoch: 57 || Training Loss:13.1002 || MSE:0.0155 || KL_Loss: 2.2463 || Val_MSE:0.0213 || time 7.8538\n",
      "epoch: 58 || Training Loss:12.7523 || MSE:0.0150 || KL_Loss: 2.2266 || Val_MSE:0.0205 || time 7.7696\n",
      "epoch: 59 || Training Loss:12.7893 || MSE:0.0150 || KL_Loss: 2.2576 || Val_MSE:0.0189 || time 8.1698\n",
      "epoch: 60 || Training Loss:12.8922 || MSE:0.0152 || KL_Loss: 2.2375 || Val_MSE:0.0200 || time 7.6695\n"
     ]
    }
   ],
   "source": [
    "training_loss_list = []\n",
    "mse_loss_list = []\n",
    "kl_loss_list = []\n",
    "val_mse_list = []\n",
    "\n",
    "\n",
    "def train(train_dataset,val_dataset = None, epochs = 50):\n",
    "  for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    epoch_mse_loss = []\n",
    "    epoch_kl_loss = []\n",
    "    epoch_val_loss=[]\n",
    "    \n",
    "    start = time.time()\n",
    "    for image_batch in train_dataset:\n",
    "      loss,MSE,KLE = train_step(image_batch)\n",
    "      epoch_loss.append(np.mean(loss))\n",
    "      epoch_mse_loss.append(np.mean(MSE))\n",
    "      epoch_kl_loss.append(np.mean(KLE))\n",
    "\n",
    "    \n",
    "    if val_dataset:\n",
    "      for image_batch in val_dataset:\n",
    "        val_mse =np.mean(val_step(image_batch))\n",
    "        epoch_val_loss.append(val_mse)\n",
    "      epoch_val_loss = np.mean(epoch_val_loss)\n",
    "\n",
    "\n",
    "    \n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    epoch_mse_loss = np.mean(epoch_mse_loss)\n",
    "    epoch_kl_loss = np.mean(epoch_kl_loss)\n",
    "    \n",
    "    training_loss_list.append(epoch_loss)\n",
    "    mse_loss_list.append(epoch_mse_loss)\n",
    "    kl_loss_list.append(epoch_kl_loss)\n",
    "    val_mse_list.append(epoch_val_loss)\n",
    "    \n",
    "    print(f'epoch: {epoch+1} || Training Loss:{epoch_loss:.4f} || MSE:{epoch_mse_loss:.4f} || KL_Loss: {epoch_kl_loss:.4f} || Val_MSE:{epoch_val_loss:.4f} || time {time.time()-start:.4f}')\n",
    "   \n",
    "  \n",
    "#train for 120 epochs \n",
    "train(normalized_train_ds, val_dataset = normalized_val_ds, epochs = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efd8ab",
   "metadata": {},
   "source": [
    "<b>VISUALIZE PERFORMANCE OF THE VAE</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f8585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_epochs = 60\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "axs[0, 0].plot(range(1,num_of_epochs+1), training_loss_list,'r')\n",
    "axs[0, 0].set_title(\"Training Loss/Epoch\")\n",
    "axs[1, 0].plot(range(1,num_of_epochs+1), mse_loss_list,'b')\n",
    "axs[1, 0].set_title(\"MSE/Epoch\")\n",
    "\n",
    "axs[0, 1].plot(range(1,num_of_epochs+1), kl_loss_list,'g')\n",
    "axs[0, 1].set_title(\"KLD Loss/Epoch\")\n",
    "axs[1, 1].plot(range(1,num_of_epochs+1), val_mse_list,'y')\n",
    "axs[1, 1].set_title(\"Validation Data MSE/Epoch\")\n",
    "fig.suptitle('Visualizing Losses During Training')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3690fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_1 = 'D:\\\\Documents\\\\DATA_SET_FOR_RELEASE\\\\renamed\\\\all_train\\\\5\\\\I359_Steel---HHA_abrasive-blasted_zirconium-pretreatment_MIL-DTL-53022_MIL-DTL-53039.jpg'\n",
    "img_1 = plt.imread(sample_img_1)\n",
    "\n",
    "sample = tf.keras.Sequential([layers.Resizing(28,28, input_shape = (512,512,3)),\n",
    "                              layers.Rescaling(scale= 1./255)])\n",
    "                             \n",
    "sample_1 = sample(np.expand_dims(img_1, axis = 0)).numpy()\n",
    "\n",
    "m, v = enc.predict(sample_1)\n",
    "latent = sampler([m,v])\n",
    "\n",
    "reconst = dec.predict(latent)\n",
    "reconst = np.reshape(reconst,(28,28,3))\n",
    "\n",
    "fig, (axs_1,axs_2) = plt.subplots(1, 2, sharey='row')\n",
    "axs_1.imshow(np.squeeze(sample_1))\n",
    "axs_1.set_title(\"Sample Image\")\n",
    "\n",
    "axs_2.imshow(reconst)\n",
    "axs_2.set_title(\"Regenerated Image\")\n",
    "fig.suptitle('Visualizing the Image from the decoder')\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6963d0",
   "metadata": {},
   "source": [
    "<b>TRAINING THE CLASSIFIERS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "860edfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Categorical, Integer, Real\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea5711",
   "metadata": {},
   "source": [
    "<b>PREPROCESSING THE DATASET FOR THE CLASSIFIERS</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "473f50ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[250, 255, 246], [239, 245, 235], [246, 247,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[244, 255, 241], [243, 249, 235], [247, 241,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[255, 249, 231], [248, 240, 221], [255, 243,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[253, 255, 247], [241, 247, 237], [244, 250,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[255, 242, 222], [246, 229, 211], [244, 230,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[[[255, 255, 250], [18, 17, 12], [18, 17, 13],...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[[[255, 252, 249], [250, 247, 242], [255, 250,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[[[255, 255, 246], [243, 239, 230], [245, 238,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[[[255, 249, 232], [251, 244, 228], [247, 245,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[[[249, 255, 238], [242, 246, 229], [244, 240,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image label\n",
       "0  [[[250, 255, 246], [239, 245, 235], [246, 247,...     5\n",
       "1  [[[244, 255, 241], [243, 249, 235], [247, 241,...     5\n",
       "2  [[[255, 249, 231], [248, 240, 221], [255, 243,...     5\n",
       "3  [[[253, 255, 247], [241, 247, 237], [244, 250,...     5\n",
       "4  [[[255, 242, 222], [246, 229, 211], [244, 230,...     5\n",
       "5  [[[255, 255, 250], [18, 17, 12], [18, 17, 13],...     5\n",
       "6  [[[255, 252, 249], [250, 247, 242], [255, 250,...     5\n",
       "7  [[[255, 255, 246], [243, 239, 230], [245, 238,...     5\n",
       "8  [[[255, 249, 232], [251, 244, 228], [247, 245,...     5\n",
       "9  [[[249, 255, 238], [242, 246, 229], [244, 240,...     5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "root_Dir = 'D:\\\\Documents\\\\DATA_SET_FOR_RELEASE\\\\renamed\\\\all_train'\n",
    "\n",
    "#Create an empty dataframe\n",
    "df = pd.DataFrame(columns=['image', 'label'])\n",
    "#Iterate over the sub directories within the root directory\n",
    "for dirs, subdirs, files in os.walk(root_Dir):\n",
    "  for file in files:\n",
    "    file_path = os.path.join(dirs, file)\n",
    "    \n",
    "    #load the image\n",
    "    with Image.open(file_path) as img:\n",
    "      #convert image to numpy array\n",
    "      img_array = np.array(img)\n",
    "      #Extract the label\n",
    "      label = os.path.basename(dirs)\n",
    "      #Add the image and label to the dataframe\n",
    "      df = df.append({'image':img_array, 'label':label}, ignore_index = True)\n",
    "# df = df.sample(frac = 1).reset_index(drop = True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5435ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 18ms/step\n",
      "17/17 [==============================] - 4s 228ms/step\n"
     ]
    }
   ],
   "source": [
    "y = df['label']\n",
    "X = df['image'].values\n",
    "X = np.stack(X)\n",
    "\n",
    "preprocessing_model = tf.keras.Sequential()\n",
    "preprocessing_model.add(tf.keras.Input(shape=(512,512,3)))\n",
    "preprocessing_model.add(tf.keras.layers.Resizing(28,28))\n",
    "preprocessing_model.add(tf.keras.layers.Rescaling(scale= 1./255))\n",
    "X1 = preprocessing_model.predict(X)\n",
    "\n",
    "a,b = enc.predict(X1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dce257",
   "metadata": {},
   "source": [
    "<b>DECISION TREE CLASSIFIER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc7f0a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.5092592592592593\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LE = LabelEncoder()\n",
    "X_train, X_test, y_train_raw, y_test_raw = train_test_split(a, y, test_size=0.2, random_state=42)\n",
    "y_train = LE.fit_transform(y_train_raw)\n",
    "y_test = LE.transform(y_test_raw)\n",
    "DT = DecisionTreeClassifier(max_leaf_nodes=5)\n",
    "DT.fit(X_train, y_train)\n",
    "DT_y_pred = DT.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy Score: ', accuracy_score(y_test, DT_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e50f773",
   "metadata": {},
   "source": [
    "<b>RANDOM FOREST CLASSIFIER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35cbc706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RF_search_space = {\"bootstrap\": Categorical([True, False]), # values for boostrap can be either True or False\n",
    "        \"max_depth\": Integer(6, 10), # values of max_depth are integers from 6 to 20\n",
    "        \"max_features\": Categorical(['auto', 'sqrt','log2']), \n",
    "        \"min_samples_leaf\": Integer(2, 8),\n",
    "        \"min_samples_split\": Integer(2, 5),\n",
    "        \"n_estimators\": Integer(350, 500)\n",
    "    }\n",
    "RF = RandomForestClassifier()\n",
    "RF_bayes_search = BayesSearchCV(RF, RF_search_space, n_iter=50, # specify how many iterations\n",
    "                                    scoring=\"accuracy\", n_jobs=-1, cv=5)\n",
    "RF_bayes_search.fit(X_train, y_train) \n",
    "RF_y_pred = RF_bayes_search.predict(X_test)\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test, RF_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e52f4b3",
   "metadata": {},
   "source": [
    "<b>SUPPORT VECTOR CLASSIFIER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "242f7478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.5740740740740741\n"
     ]
    }
   ],
   "source": [
    "SVM = SVC()\n",
    "SVM_search_space = {'C':Real(0.01,2),\n",
    "                    'kernel':Categorical(['linear','rbf'])}\n",
    "SVM_bayes_search = BayesSearchCV(SVM, SVM_search_space, n_iter = 50, n_jobs = -1, cv = cv,\n",
    "                                scoring = 'accuracy')\n",
    "SVM_bayes_search.fit(X_train, y_train)\n",
    "\n",
    "SVM_y_pred = SVM_bayes_search.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test, SVM_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f40fd4",
   "metadata": {},
   "source": [
    "<b>NEAREST NEIGHBORS CLASSIFIER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f406292c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "KNN_search_space = {'n_neighbors':Integer(35,45),\n",
    "                  }\n",
    "KNN_bayes_search = BayesSearchCV(KNN, KNN_search_space, n_iter = 50, n_jobs = -1, cv = cv, \n",
    "                                scoring ='accuracy')\n",
    "KNN_bayes_search.fit(X_train, y_train)\n",
    "KNN_y_pred = KNN_bayes_search.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test, KNN_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18872060",
   "metadata": {},
   "source": [
    "<b>LOGISTIC REGRESSION CLASSIFIER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab42d0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.5740740740740741\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LR = LogisticRegression()\n",
    "LR_search_space = {'C':Real(0.01,1),\n",
    "                    'penalty':Categorical(['l2','none']),\n",
    "                    'max_iter':Integer(50,150),\n",
    "                    'l1_ratio': Real(0,1)}\n",
    "LR_bayes_search = BayesSearchCV(LR, LR_search_space, n_iter = 50, n_jobs = -1, cv = 5,\n",
    "                                scoring = 'accuracy')\n",
    "LR_bayes_search.fit(X_train, y_train)\n",
    "\n",
    "LR_y_pred = LR_bayes_search.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test,LR_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a39e4f",
   "metadata": {},
   "source": [
    "<b>EXTREME GRADIENT BOOST CLASSIFIER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734ce4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.6018518518518519\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LE = LabelEncoder()\n",
    "xgb_y_train = LE.fit_transform(y_train)\n",
    "xgb_y_test = LE.transform(y_test)\n",
    "XGB = xgboost.XGBClassifier()\n",
    "\n",
    "XGB_search_space = {\n",
    "                   'max_depth':Integer(3,10),\n",
    "                    'n_estimators':Integer(100,800)\n",
    "                   }\n",
    "XGB_bayes_search = BayesSearchCV(XGB, XGB_search_space, n_iter = 50, n_jobs = -1, cv = 5,\n",
    "                                scoring = 'accuracy')\n",
    "XGB_bayes_search.fit(X_train,y_train)\n",
    "\n",
    "XGB_y_pred  = XGB_bayes_search.predict(X_test)\n",
    "\n",
    "\n",
    "print('Accuracy Score: ',accuracy_score(y_test,XGB_y_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afbf40b",
   "metadata": {},
   "source": [
    "<b>VOTING CLASSIFIER</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fb21008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VC_hard_accuracy: 0.6018518518518519\n",
      "VC_soft_accuracy: 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "\n",
    "RF_params = dict(RF_bayes_search.best_params_)\n",
    "KNN_params = dict(KNN_bayes_search.best_params_)\n",
    "SVM_params = dict(SVM_bayes_search.best_params_)\n",
    "LR_params = dict(LR_bayes_search.best_params_)\n",
    "XGB_params = dict(XGB_bayes_search.best_params_)\n",
    "\n",
    "\n",
    "estimator = []\n",
    "\n",
    "estimator.append(('RF', RandomForestClassifier(bootstrap=RF_params['bootstrap'],\n",
    "                                                max_depth=RF_params['max_depth'],\n",
    "                                                max_features=RF_params['max_features'],\n",
    "                                                min_samples_leaf = RF_params['min_samples_leaf'],\n",
    "                                                min_samples_split=RF_params['min_samples_split'],\n",
    "                                                n_estimators =  RF_params['n_estimators'])))\n",
    "\n",
    "estimator.append(('SVM', SVC(C=SVM_params['C'],\n",
    "                             kernel=SVM_params['kernel'],\n",
    "                            probability=True)))\n",
    "\n",
    "estimator.append(('KNN', KNeighborsClassifier(n_neighbors=KNN_params['n_neighbors'])))\n",
    "\n",
    "# estimator.append(('LR', LogisticRegression(C=LR_params['C'],\n",
    "#                                            l1_ratio=LR_params['l1_ratio'],\n",
    "#                                            max_iter=LR_params['max_iter'],\n",
    "#                                            penalty = LR_params['penalty'])))\n",
    "estimator.append(('XGB', xgboost.XGBClassifier(max_depth=XGB_params['max_depth'],\n",
    "                                              n_estimators = XGB_params['n_estimators'],\n",
    "                                              objective='multi: softprob')))\n",
    "\n",
    "VC_hard = VotingClassifier(estimators = estimator, voting = 'hard')\n",
    "VC_soft = VotingClassifier(estimators = estimator, voting = 'soft')\n",
    "\n",
    "VC_hard.fit(X_train, y_train)\n",
    "VC_soft.fit(X_train, y_train)\n",
    "\n",
    "VC_hard_pred = VC_hard.predict(X_test)\n",
    "VC_soft_pred = VC_soft.predict(X_test)\n",
    "\n",
    "print(f'VC_hard_accuracy: {accuracy_score(y_test,VC_hard_pred)}')\n",
    "print(f'VC_soft_accuracy: {accuracy_score(y_test,VC_soft_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869ad83f",
   "metadata": {},
   "source": [
    "<b>RESULT FROM HYPER PARAMETER SEARCH</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82f2fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Hyper-parameters: {'bootstrap': False, 'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 429}\n",
      "\n",
      "\n",
      "SVM Hyper-parameters: {'C': 0.6884994507042697, 'kernel': 'rbf'}\n",
      "\n",
      "\n",
      "KNN Hyper-parameters: {'n_neighbors': 39}\n",
      "\n",
      "\n",
      "LR Hyper-parameters: {'C': 0.08675856128137853, 'l1_ratio': 0.9184426487737988, 'max_iter': 71, 'penalty': 'none'}\n",
      "\n",
      "\n",
      "XGB Hyper-parameters: {'max_depth': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print('RF Hyper-parameters:', dict(RF_bayes_search.best_params_))\n",
    "print('\\n\\nSVM Hyper-parameters:', dict(SVM_bayes_search.best_params_))\n",
    "print('\\n\\nKNN Hyper-parameters:', dict(KNN_bayes_search.best_params_))\n",
    "print('\\n\\nLR Hyper-parameters:', dict(LR_bayes_search.best_params_))\n",
    "print('\\n\\nXGB Hyper-parameters:', dict(XGB_bayes_search.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
